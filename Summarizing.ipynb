{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyVxJwnO+KAjj3rWaZhrRh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtpradoc/ChatGPT/blob/main/Summarizing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarizing"
      ],
      "metadata": {
        "id": "DAGdrbrCn500"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will summarize text with a focus on specific topics."
      ],
      "metadata": {
        "id": "ez-REkSEn5jF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "apg4lzT0pI0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQC7D3X2pRtl",
        "outputId": "7ef84355-0585-4a98-e7f3-858492c4a9ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sHTgIjX_nr9_"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"): #Andrew mentioned that the prompt/ completion paradign is preferable for this class\n",
        "  messages = [{\"role\":\"user\", \"content\":prompt}]\n",
        "  response = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0, #this is the degree of randomness of the model's output\n",
        "  )\n",
        "  return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "ZNpAgW6QpQvn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text to summarize"
      ],
      "metadata": {
        "id": "UuL_EMORqJlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prod_review = f\"\"\"\n",
        "Got this panda plush toy for my daughter's birthday, \\\n",
        "who loves it and takes it everywhere. It's soft and \\\n",
        "super cute, and its face has a friendly look. It's \\\n",
        "a bit small for what I paid though. I think there\n",
        "might be other options that are bigger for the \\\n",
        "same price. It arrived a day earlier than expected, \\\n",
        "so I got to play with it myself before I gave it \\\n",
        "to her.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uVJoIr3BqI6r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize with a word/sentence/character limit"
      ],
      "metadata": {
        "id": "-1ysdwWUqveG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5uc5rbfquYI",
        "outputId": "c8acb150-c030-498b-d152-3e35243341f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft and cute panda plush toy loved by daughter, but a bit small for the price. Arrived early.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize with a focus on shipping and delivery"
      ],
      "metadata": {
        "id": "854piuxMtK9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site to give feedback to the \\\n",
        "Shipping department.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words and focusing on any aspects \\\n",
        "that mention shipping and delivery of the product.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmS9KLvWrKcT",
        "outputId": "79529587-c266-4c15-c1f9-4fa4ef2cf2f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The panda plush toy arrived a day earlier than expected, but the customer felt it was a bit small for the price paid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize with a focus on price and value"
      ],
      "metadata": {
        "id": "CNtuB_vstjgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a product \\\n",
        "review from an ecommerce site to give feedback to the \\\n",
        "pricing department, responsible for determinig the \\\n",
        "price of the product.\n",
        "\n",
        "Summarize the review below, delimited by triple\n",
        "backticks, in at most 30 words and focusing on any aspects \\\n",
        "that are relevant to the price and perceived value.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDJyOFLktgbn",
        "outputId": "bef254c5-c6f5-442e-a422-e168ea864b8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```Soft and cute panda plush toy loved by daughter, but a bit small for the price paid. Other options may offer better value.```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment**"
      ],
      "metadata": {
        "id": "KnNXJ7PEt6Xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Summaries include topics that are not related to the topic of focus.\n",
        "\n"
      ],
      "metadata": {
        "id": "79v4rooXt8uB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Try \"extract\" instead of \"summarize\""
      ],
      "metadata": {
        "id": "nHp-wsWUusUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to extract relevant information from \\\n",
        "a product review from an ecommerce site to give \\\n",
        "feedback to the Shipping department.\n",
        "\n",
        "From the review below, delimited by triple quotes \\\n",
        "extract the information relevant to shipping and \\\n",
        "delivery. Limit to 30 words.\n",
        "\n",
        "Review: ```{prod_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsbLy_hDt3Xo",
        "outputId": "291aa1f2-7460-47af-d455-f3de735fe0a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product arrived a day earlier than expected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize multiple product reviews"
      ],
      "metadata": {
        "id": "JagbJTU1vw77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_1 = prod_review\n",
        "\n",
        "# review for a standing lamp\n",
        "review_2 = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one \\\n",
        "had additional storage and not too high of a price \\\n",
        "point. Got it fast - arrived in 2 days. The string \\\n",
        "to the lamp broke during the transit and the company \\\n",
        "happily sent over a new one. Came within a few days \\\n",
        "as well. It was easy to put together. Then I has a \\\n",
        "missing part, so I contacted their support and they \\\n",
        "very quickly got e te missing piece! Seems to me \\\n",
        "to be a great company that cares about their customers \\\n",
        "and products.\n",
        "\"\"\"\n",
        "\n",
        "# review for an electric tootbrush\n",
        "review_3 = \"\"\"\n",
        "My dental hygienist recommended an electric toothbrush, \\\n",
        "which is why I got this. The battery life seems to be \\\n",
        "pretty impressive so far. After initial charging and \\\n",
        "leaving the charger plugged in for the first weel to \\\n",
        "condition the battery, i've unplugged the charger and \\\n",
        "been using it for twice daily brushing for the last \\\n",
        "3 weeks all on the same charge. But the toothbrush head \\\n",
        "is too small. I've seen baby toothbrushes bigger than \\\n",
        "this one. I wish the head was bigger with different \\\n",
        "length bristles to get between teeth better because \\\n",
        "this one doesn't. Overall if you can get this one \\\n",
        "around the $50 mark, it's a good deal. The manufactuer's \\\n",
        "replacements heads are pretty expensive, but you can \\\n",
        "get generic ones that're more reasonably priced. This \\\n",
        "toothbrush make me feeel like I've been to the dentist \\\n",
        "every day. My teeth feel sparkly clean!\n",
        "\"\"\"\n",
        "\n",
        "# review for a blender\n",
        "review_4 = \"\"\"\n",
        "So, they still had the 17 piece system on seasonal \\\n",
        "sale for around $49 in the month of November, about \\\n",
        "half off, but for some reason (call it price gouging) \\\n",
        "around the second week of December the prices all went \\\n",
        "up to about anywhere from between $70-$89 for the same \\\n",
        "system. And the 11 piece system went up around $10 or \\\n",
        "so in price also from the earlier sale price of $29. \\\n",
        "So it looks okay, but if you look at the base, the part \\\n",
        "where the blade locks into place doesnâ€™t look as good \\\n",
        "as in previous editions from a few years ago, but I \\\n",
        "plan to be very gentle with it (example, I crush \\\n",
        "very hard items like beans, ice, rice, etc. in the \\ \n",
        "blender first then pulverize them in the serving size \\\n",
        "I want in the blender then switch to the whipping \\\n",
        "blade for a finer flour, and use the cross cutting blade \\\n",
        "first when making smoothies, then use the flat blade \\\n",
        "if I need them finer/less pulpy). Special tip when making \\\n",
        "smoothies, finely cut and freeze the fruits and \\\n",
        "vegetables (if using spinach-lightly stew soften the \\ \n",
        "spinach then freeze until ready for use-and if making \\\n",
        "sorbet, use a small to medium sized food processor) \\ \n",
        "that you plan to use that way you can avoid adding so \\\n",
        "much ice if at all-when making your smoothie. \\\n",
        "After about a year, the motor was making a funny noise. \\\n",
        "I called customer service but the warranty expired \\\n",
        "already, so I had to buy another one. FYI: The overall \\\n",
        "quality has gone done in these types of products, so \\\n",
        "they are kind of counting on brand recognition and \\\n",
        "consumer loyalty to maintain sales. Got it in about \\\n",
        "two days.\n",
        "\"\"\"\n",
        "\n",
        "reviews = [review_1, review_2, review_3, review_4]"
      ],
      "metadata": {
        "id": "PqL-st8Wvuyb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(reviews)):\n",
        "  prompt = f\"\"\"\n",
        "  Your task is to generate a short summary of a product \\ \n",
        "  review from an ecommerce site. \n",
        "\n",
        "  Summarize the review below, delimited by triple \\\n",
        "  backticks in at most 20 words. \n",
        "\n",
        "  Review: ```{reviews[i]}```\n",
        "  \"\"\"\n",
        "\n",
        "  response = get_completion(prompt)\n",
        "  print(i, response, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "rI6dOCifyTaj",
        "outputId": "efee56a8-f382-4826-e897-bf2399e46e7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Soft and cute panda plush toy loved by daughter, but small for price. Arrived early. \n",
            "\n",
            "1 Affordable lamp with storage, fast shipping, and excellent customer service. Easy to assemble with quick replacement parts. \n",
            "\n",
            "2 Good battery life, small toothbrush head, good deal if bought around $50, feels like a dentist clean. \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d27dd65be2f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ef01d77db888>\u001b[0m in \u001b[0;36mget_completion\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#Andrew mentioned that the prompt/ completion paradign is preferable for this class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             return (\n\u001b[0;32m--> 624\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    625\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-BGOzcbL21X1merdfz2kf5Rt9 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OD8wDB9yoaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}